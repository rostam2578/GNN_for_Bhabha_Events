2: gpu017.ihep.ac.cn
4: gpu017.ihep.ac.cn
1: gpu017.ihep.ac.cn
3: gpu017.ihep.ac.cn
5: gpu017.ihep.ac.cn
7: gpu017.ihep.ac.cn
0: gpu017.ihep.ac.cn
6: gpu017.ihep.ac.cn
8: gpu017.ihep.ac.cn
9: gpu017.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-c8eed28e-aee2-6a6a-9751-8500b0767218)
GPU 1: Tesla V100-SXM2-32GB (UUID: GPU-bc65658a-1f98-a96e-7a36-fcda619976d2)
GPU 2: Tesla V100-SXM2-32GB (UUID: GPU-9b0f04f7-899c-4abe-3f03-f1b4eff10083)
GPU 3: Tesla V100-SXM2-32GB (UUID: GPU-56f30f69-2784-b877-7bb3-eed9c35b600b)
GPU 4: Tesla V100-SXM2-32GB (UUID: GPU-777316b4-ab5c-8c1a-4376-f4c385f36a63)
Allocate GPU cards : 0,1,2,3,4

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        450.36.06
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.8
srcversion:     BB5CB243542347D4EB0C79C
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_MapRegistersEarly:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_EnableBacklightHandler:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_AssignGpus:charp

nvidia-smi:
Sun Jun  6 08:24:29 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:1C:00.0 Off |                    0 |
| N/A   38C    P0    44W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  On   | 00000000:1D:00.0 Off |                    0 |
| N/A   39C    P0    45W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  On   | 00000000:1E:00.0 Off |                    0 |
| N/A   39C    P0    45W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  On   | 00000000:1F:00.0 Off |                    0 |
| N/A   39C    P0    45W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |
| N/A   36C    P0    44W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Wed_Jul_22_19:09:09_PDT_2020
Cuda compilation tools, release 11.0, V11.0.221
Build cuda_11.0_bu.TC445_37.28845127_0

 torch version: 1.8.0+cu111

 cuda version: 11.1

 is cuda available: True

 CUDNN VERSION: 8005

 Number CUDA Devices: 5

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089730048

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b1777a558b0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/cuda-11

real	1m58.851s
user	0m3.442s
sys	0m10.898s
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-qdbm9u56 because the default path (/afs/ihep.ac.cn/users/h/hoseinkk/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib is building the font cache; this may take a moment.




 Training ... 






 The graph ... 


graph forming time: 0:00:14.617123
Number of nodes: 1849
Number of edges: 14534
Average node degree: 7.86
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
contains self/isolated loop: False, False
is coalesced: False
number of features, per nodes, per edges: (1, 1, 0)
x: tensor([[0.0000e+00],
        [1.0000e+00],
        [2.0000e+00],
        ...,
        [1.8460e+03],
        [1.8470e+03],
        [1.8480e+03]]) 
 edge_index: tensor([[1605, 1687, 1365,  ..., 1602, 1729,  308],
        [1649, 1688, 1408,  ..., 1644, 1685,  265]])





 Loading data ... 






 The Network ... 


Net(
  (conv1): GCNConv(1, 256)
  (conv2): GCNConv(256, 256)
  (conv3): GCNConv(256, 128)
  (conv4): GCNConv(128, 64)
  (conv5): GCNConv(64, 32)
  (conv6): GCNConv(32, 1)
)

Passing two sample data from the network before training 
result1: tensor([[[0.5000],
         [0.5000],
         [0.4999],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]]], device='cuda:0', dtype=torch.float64,
       grad_fn=<SigmoidBackward>) 
data1: Data(edge_index=[2, 14534], x=[2, 1849, 1]) torch.Size([2, 1849, 1]) 
x.shape: torch.Size([1849, 1])
tensor([[0.5000, 0.5000, 0.4999,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.4999, 0.4999,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.4999, 0.4999,  ..., 0.5000, 0.5000, 0.5000],
        ...,
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ViewBackward>)
=> loading checkpoint from /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04/saved_checkpoint.pth.tar
epoch: 0 batch 0.0 event: 0 loss: tensor(0.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 1.0 event: 10000 loss: tensor(0.0760, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 2.0 event: 20000 loss: tensor(0.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 4.0 event: 40000 loss: tensor(0.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 5.0 event: 50000 loss: tensor(0.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 6.0 event: 60000 loss: tensor(0.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 7.0 event: 70000 loss: tensor(0.0681, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:02:17.958127
epoch: 0 mean loss: 0.07415093871149102
=> saveing checkpoint at epoch 0
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 1 batch 0.0 event: 0 loss: tensor(0.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 1.0 event: 10000 loss: tensor(0.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 2.0 event: 20000 loss: tensor(0.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 4.0 event: 40000 loss: tensor(0.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 5.0 event: 50000 loss: tensor(0.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 6.0 event: 60000 loss: tensor(0.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 7.0 event: 70000 loss: tensor(0.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:04:36.545031
epoch: 1 mean loss: 0.07417155327148214
epoch: 2 batch 0.0 event: 0 loss: tensor(0.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 1.0 event: 10000 loss: tensor(0.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 2.0 event: 20000 loss: tensor(0.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 3.0 event: 30000 loss: tensor(0.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 4.0 event: 40000 loss: tensor(0.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 5.0 event: 50000 loss: tensor(0.0801, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 7.0 event: 70000 loss: tensor(0.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:06:55.652617
epoch: 2 mean loss: 0.07413302665458828
epoch: 3 batch 0.0 event: 0 loss: tensor(0.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 2.0 event: 20000 loss: tensor(0.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 4.0 event: 40000 loss: tensor(0.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 5.0 event: 50000 loss: tensor(0.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 7.0 event: 70000 loss: tensor(0.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:09:14.837828
epoch: 3 mean loss: 0.0741070645609848
=> saveing checkpoint at epoch 3
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 4 batch 0.0 event: 0 loss: tensor(0.0815, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 1.0 event: 10000 loss: tensor(0.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 2.0 event: 20000 loss: tensor(0.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 4.0 event: 40000 loss: tensor(0.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 5.0 event: 50000 loss: tensor(0.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 6.0 event: 60000 loss: tensor(0.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 7.0 event: 70000 loss: tensor(0.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:11:34.048401
epoch: 4 mean loss: 0.07413247543268714
epoch: 5 batch 0.0 event: 0 loss: tensor(0.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 1.0 event: 10000 loss: tensor(0.0763, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 2.0 event: 20000 loss: tensor(0.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 3.0 event: 30000 loss: tensor(0.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 4.0 event: 40000 loss: tensor(0.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 5.0 event: 50000 loss: tensor(0.0797, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 6.0 event: 60000 loss: tensor(0.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 7.0 event: 70000 loss: tensor(0.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:13:53.199846
epoch: 5 mean loss: 0.07412245451235638
epoch: 6 batch 0.0 event: 0 loss: tensor(0.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 2.0 event: 20000 loss: tensor(0.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 4.0 event: 40000 loss: tensor(0.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 5.0 event: 50000 loss: tensor(0.0804, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 6.0 event: 60000 loss: tensor(0.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 7.0 event: 70000 loss: tensor(0.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:16:12.344820
epoch: 6 mean loss: 0.07412052141763399
=> saveing checkpoint at epoch 6
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 7 batch 0.0 event: 0 loss: tensor(0.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 1.0 event: 10000 loss: tensor(0.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 2.0 event: 20000 loss: tensor(0.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 3.0 event: 30000 loss: tensor(0.0778, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 4.0 event: 40000 loss: tensor(0.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 5.0 event: 50000 loss: tensor(0.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 7.0 event: 70000 loss: tensor(0.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:18:31.462587
epoch: 7 mean loss: 0.07418792189928422
epoch: 8 batch 0.0 event: 0 loss: tensor(0.0830, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 2.0 event: 20000 loss: tensor(0.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 3.0 event: 30000 loss: tensor(0.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 4.0 event: 40000 loss: tensor(0.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 5.0 event: 50000 loss: tensor(0.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 7.0 event: 70000 loss: tensor(0.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:20:50.586115
epoch: 8 mean loss: 0.07417605016883548
epoch: 9 batch 0.0 event: 0 loss: tensor(0.0822, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 1.0 event: 10000 loss: tensor(0.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 2.0 event: 20000 loss: tensor(0.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 4.0 event: 40000 loss: tensor(0.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 5.0 event: 50000 loss: tensor(0.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 6.0 event: 60000 loss: tensor(0.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 7.0 event: 70000 loss: tensor(0.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:23:09.674995
epoch: 9 mean loss: 0.07415191173097949
=> saveing checkpoint at epoch 9
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 10 batch 0.0 event: 0 loss: tensor(0.0823, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 1.0 event: 10000 loss: tensor(0.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 2.0 event: 20000 loss: tensor(0.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 4.0 event: 40000 loss: tensor(0.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 5.0 event: 50000 loss: tensor(0.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 6.0 event: 60000 loss: tensor(0.0737, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 7.0 event: 70000 loss: tensor(0.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:25:28.779274
epoch: 10 mean loss: 0.07420214405509595
epoch: 11 batch 0.0 event: 0 loss: tensor(0.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 1.0 event: 10000 loss: tensor(0.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 2.0 event: 20000 loss: tensor(0.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 4.0 event: 40000 loss: tensor(0.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 5.0 event: 50000 loss: tensor(0.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 7.0 event: 70000 loss: tensor(0.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:27:47.868149
epoch: 11 mean loss: 0.07414502863710347
epoch: 12 batch 0.0 event: 0 loss: tensor(0.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 2.0 event: 20000 loss: tensor(0.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 4.0 event: 40000 loss: tensor(0.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 5.0 event: 50000 loss: tensor(0.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 7.0 event: 70000 loss: tensor(0.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:30:06.953629
epoch: 12 mean loss: 0.07411090632853552
=> saveing checkpoint at epoch 12
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 13 batch 0.0 event: 0 loss: tensor(0.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 2.0 event: 20000 loss: tensor(0.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 4.0 event: 40000 loss: tensor(0.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 5.0 event: 50000 loss: tensor(0.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 6.0 event: 60000 loss: tensor(0.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 7.0 event: 70000 loss: tensor(0.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:32:26.035210
epoch: 13 mean loss: 0.07416902903721659
epoch: 14 batch 0.0 event: 0 loss: tensor(0.0817, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 1.0 event: 10000 loss: tensor(0.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 2.0 event: 20000 loss: tensor(0.0696, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 4.0 event: 40000 loss: tensor(0.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 5.0 event: 50000 loss: tensor(0.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 6.0 event: 60000 loss: tensor(0.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 7.0 event: 70000 loss: tensor(0.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:34:45.101749
epoch: 14 mean loss: 0.07415747029930465
epoch: 15 batch 0.0 event: 0 loss: tensor(0.0819, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 2.0 event: 20000 loss: tensor(0.0699, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 3.0 event: 30000 loss: tensor(0.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 4.0 event: 40000 loss: tensor(0.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 5.0 event: 50000 loss: tensor(0.0811, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 7.0 event: 70000 loss: tensor(0.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:37:04.140562
epoch: 15 mean loss: 0.07417425752947798
=> saveing checkpoint at epoch 15
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 16 batch 0.0 event: 0 loss: tensor(0.0827, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 1.0 event: 10000 loss: tensor(0.0765, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 2.0 event: 20000 loss: tensor(0.0698, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 4.0 event: 40000 loss: tensor(0.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 5.0 event: 50000 loss: tensor(0.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 7.0 event: 70000 loss: tensor(0.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:39:23.249133
epoch: 16 mean loss: 0.07414294001319263
epoch: 17 batch 0.0 event: 0 loss: tensor(0.0824, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 2.0 event: 20000 loss: tensor(0.0704, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 4.0 event: 40000 loss: tensor(0.0745, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 5.0 event: 50000 loss: tensor(0.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 7.0 event: 70000 loss: tensor(0.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:41:42.295372
epoch: 17 mean loss: 0.07414350505576948
epoch: 18 batch 0.0 event: 0 loss: tensor(0.0838, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 2.0 event: 20000 loss: tensor(0.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 4.0 event: 40000 loss: tensor(0.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 5.0 event: 50000 loss: tensor(0.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 7.0 event: 70000 loss: tensor(0.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:44:01.414559
epoch: 18 mean loss: 0.07417172840837921
=> saveing checkpoint at epoch 18
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 19 batch 0.0 event: 0 loss: tensor(0.0833, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 1.0 event: 10000 loss: tensor(0.0755, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 2.0 event: 20000 loss: tensor(0.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 4.0 event: 40000 loss: tensor(0.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 5.0 event: 50000 loss: tensor(0.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 7.0 event: 70000 loss: tensor(0.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:46:20.602268
epoch: 19 mean loss: 0.07411461904092256
=> saveing checkpoint at epoch 19
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] [0.07415094 0.07417155 0.07413303 0.07410706 0.07413248 0.07412245
 0.07412052 0.07418792 0.07417605 0.07415191 0.07420214 0.07414503
 0.07411091 0.07416903 0.07415747 0.07417426 0.07414294 0.07414351
 0.07417173 0.07411462]
0:46:20.964749

real	47m37.794s
user	32m49.980s
sys	13m50.758s
