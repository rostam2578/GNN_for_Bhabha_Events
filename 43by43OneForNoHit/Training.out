0: gpu031.ihep.ac.cn
GPU 0: Tesla V100-SXM2-32GB (UUID: GPU-5b43a0f9-4a91-a5b1-d55f-36a3630aded9)
GPU 1: Tesla V100-SXM2-32GB (UUID: GPU-dcfe2e79-d868-8e74-bef9-0ff88d9ba39f)
GPU 2: Tesla V100-SXM2-32GB (UUID: GPU-ac85de2a-35c8-297a-79db-3250d7abcb16)
GPU 3: Tesla V100-SXM2-32GB (UUID: GPU-6a8b37c1-dc08-9ec1-db57-64a21f01a4ec)
GPU 4: Tesla V100-SXM2-32GB (UUID: GPU-c3328cc0-6d96-e175-21d8-3ddd5b25b878)
Allocate GPU cards : 0,1,2,3,4

modinfo:
filename:       /lib/modules/3.10.0-1127.8.2.el7.x86_64/extra/nvidia.ko.xz
alias:          char-major-195-*
version:        450.36.06
supported:      external
license:        NVIDIA
retpoline:      Y
rhelversion:    7.8
srcversion:     BB5CB243542347D4EB0C79C
alias:          pci:v000010DEd*sv*sd*bc03sc02i00*
alias:          pci:v000010DEd*sv*sd*bc03sc00i00*
depends:        
vermagic:       3.10.0-1127.8.2.el7.x86_64 SMP mod_unload modversions 
parm:           NvSwitchRegDwords:NvSwitch regkey (charp)
parm:           NvSwitchBlacklist:NvSwitchBlacklist=uuid[,uuid...] (charp)
parm:           NVreg_ResmanDebugLevel:int
parm:           NVreg_RmLogonRC:int
parm:           NVreg_ModifyDeviceFiles:int
parm:           NVreg_DeviceFileUID:int
parm:           NVreg_DeviceFileGID:int
parm:           NVreg_DeviceFileMode:int
parm:           NVreg_InitializeSystemMemoryAllocations:int
parm:           NVreg_UsePageAttributeTable:int
parm:           NVreg_MapRegistersEarly:int
parm:           NVreg_RegisterForACPIEvents:int
parm:           NVreg_EnablePCIeGen3:int
parm:           NVreg_EnableMSI:int
parm:           NVreg_TCEBypassMode:int
parm:           NVreg_EnableStreamMemOPs:int
parm:           NVreg_EnableBacklightHandler:int
parm:           NVreg_RestrictProfilingToAdminUsers:int
parm:           NVreg_PreserveVideoMemoryAllocations:int
parm:           NVreg_DynamicPowerManagement:int
parm:           NVreg_DynamicPowerManagementVideoMemoryThreshold:int
parm:           NVreg_EnableUserNUMAManagement:int
parm:           NVreg_MemoryPoolSize:int
parm:           NVreg_KMallocHeapMaxSize:int
parm:           NVreg_VMallocHeapMaxSize:int
parm:           NVreg_IgnoreMMIOCheck:int
parm:           NVreg_NvLinkDisable:int
parm:           NVreg_EnablePCIERelaxedOrderingMode:int
parm:           NVreg_RegisterPCIDriver:int
parm:           NVreg_RegistryDwords:charp
parm:           NVreg_RegistryDwordsPerDevice:charp
parm:           NVreg_RmMsg:charp
parm:           NVreg_GpuBlacklist:charp
parm:           NVreg_TemporaryFilePath:charp
parm:           NVreg_AssignGpus:charp

nvidia-smi:
Fri Jun  4 22:15:41 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.36.06    Driver Version: 450.36.06    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:3A:00.0 Off |                    0 |
| N/A   29C    P0    40W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |
| N/A   31C    P0    42W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
| N/A   30C    P0    40W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
| N/A   30C    P0    42W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-SXM2...  On   | 00000000:B2:00.0 Off |                    0 |
| N/A   28C    P0    41W / 300W |      0MiB / 32510MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

nvcc --version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Wed_Jul_22_19:09:09_PDT_2020
Cuda compilation tools, release 11.0, V11.0.221
Build cuda_11.0_bu.TC445_37.28845127_0

 torch version: 1.8.0+cu111

 cuda version: 11.1

 is cuda available: True

 CUDNN VERSION: 8005

 Number CUDA Devices: 5

 CUDA Device Name: Tesla V100-SXM2-32GB

 CUDA Device Total Memory [GB]: 34.089730048

 Device capability: (7, 0) 

 Cuda deviice: <torch.cuda.device object at 0x2b724d1337c0> 

 Is cuda initialized: True

 CUDA_HOME: /hpcfs/bes/mlgpu/hoseinkk/cuda-11

real	1m21.034s
user	0m2.321s
sys	0m9.473s




 The graph ... 


graph forming time: 0:00:13.338867
Number of nodes: 1849
Number of edges: 14534
Average node degree: 7.86
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
contains self/isolated loop: False, False
is coalesced: False
number of features, per nodes, per edges: (1, 1, 0)
x: tensor([[0.0000e+00],
        [1.0000e+00],
        [2.0000e+00],
        ...,
        [1.8460e+03],
        [1.8470e+03],
        [1.8480e+03]]) 
 edge_index: tensor([[1605, 1687, 1365,  ..., 1602, 1729,  308],
        [1649, 1688, 1408,  ..., 1644, 1685,  265]])

real	0m23.571s
user	0m4.503s
sys	0m4.854s





 Loading data ... 



real	0m13.556s
user	0m4.558s
sys	0m4.171s
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-mqeb9suq because the default path (/afs/ihep.ac.cn/users/h/hoseinkk/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.




 The Network ... 






 The graph ... 


graph forming time: 0:00:03.466621
Number of nodes: 1849
Number of edges: 14534
Average node degree: 7.86
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
contains self/isolated loop: False, False
is coalesced: False
number of features, per nodes, per edges: (1, 1, 0)
x: tensor([[0.0000e+00],
        [1.0000e+00],
        [2.0000e+00],
        ...,
        [1.8460e+03],
        [1.8470e+03],
        [1.8480e+03]]) 
 edge_index: tensor([[1605, 1687, 1365,  ..., 1602, 1729,  308],
        [1649, 1688, 1408,  ..., 1644, 1685,  265]])





 Loading data ... 


Net(
  (conv1): GCNConv(1, 256)
  (conv2): GCNConv(256, 256)
  (conv3): GCNConv(256, 128)
  (conv4): GCNConv(128, 64)
  (conv5): GCNConv(64, 32)
  (conv6): GCNConv(32, 1)
)

Passing two sample data from the network before training 
result1: tensor([[[0.5000],
         [0.4999],
         [0.4998],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]]], device='cuda:0', dtype=torch.float64,
       grad_fn=<SigmoidBackward>) 
data1: Data(edge_index=[2, 14534], x=[2, 1849, 1]) torch.Size([2, 1849, 1]) 
x.shape: torch.Size([1849, 1])
tensor([[0.5000, 0.4999, 0.4998,  ..., 0.4999, 0.5000, 0.5000],
        [0.5000, 0.4999, 0.4997,  ..., 0.4999, 0.5000, 0.5000],
        [0.4999, 0.4999, 0.4997,  ..., 0.4999, 0.5000, 0.5000],
        ...,
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ViewBackward>)

real	0m25.209s
user	0m8.235s
sys	0m5.144s
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-q_3q_36w because the default path (/afs/ihep.ac.cn/users/h/hoseinkk/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.




 Training ... 






 The graph ... 


graph forming time: 0:00:03.468249
Number of nodes: 1849
Number of edges: 14534
Average node degree: 7.86
Contains isolated nodes: False
Contains self-loops: False
Is undirected: True
contains self/isolated loop: False, False
is coalesced: False
number of features, per nodes, per edges: (1, 1, 0)
x: tensor([[0.0000e+00],
        [1.0000e+00],
        [2.0000e+00],
        ...,
        [1.8460e+03],
        [1.8470e+03],
        [1.8480e+03]]) 
 edge_index: tensor([[1605, 1687, 1365,  ..., 1602, 1729,  308],
        [1649, 1688, 1408,  ..., 1644, 1685,  265]])





 Loading data ... 






 The Network ... 


Net(
  (conv1): GCNConv(1, 256)
  (conv2): GCNConv(256, 256)
  (conv3): GCNConv(256, 128)
  (conv4): GCNConv(128, 64)
  (conv5): GCNConv(64, 32)
  (conv6): GCNConv(32, 1)
)

Passing two sample data from the network before training 
result1: tensor([[[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]],

        [[0.5000],
         [0.5000],
         [0.5000],
         ...,
         [0.5000],
         [0.5000],
         [0.5000]]], device='cuda:0', dtype=torch.float64,
       grad_fn=<SigmoidBackward>) 
data1: Data(edge_index=[2, 14534], x=[2, 1849, 1]) torch.Size([2, 1849, 1]) 
x.shape: torch.Size([1849, 1])
tensor([[0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5001,  ..., 0.5000, 0.5000, 0.5000],
        ...,
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000]],
       device='cuda:0', dtype=torch.float64, grad_fn=<ViewBackward>)
epoch: 0 batch 0.0 event: 0 loss: tensor(0.6932, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 1.0 event: 10000 loss: tensor(0.1308, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 2.0 event: 20000 loss: tensor(0.0844, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 3.0 event: 30000 loss: tensor(0.0888, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 4.0 event: 40000 loss: tensor(0.0818, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 5.0 event: 50000 loss: tensor(0.0865, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 6.0 event: 60000 loss: tensor(0.0778, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 0 batch 7.0 event: 70000 loss: tensor(0.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:02:16.651564
epoch: 0 mean loss: 0.10107409511063382
=> saveing checkpoint at epoch 0
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 1 batch 0.0 event: 0 loss: tensor(0.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 1.0 event: 10000 loss: tensor(0.0784, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 2.0 event: 20000 loss: tensor(0.0725, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 3.0 event: 30000 loss: tensor(0.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 4.0 event: 40000 loss: tensor(0.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 5.0 event: 50000 loss: tensor(0.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 6.0 event: 60000 loss: tensor(0.0766, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 1 batch 7.0 event: 70000 loss: tensor(0.0688, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:04:33.225401
epoch: 1 mean loss: 0.07661866279490154
epoch: 2 batch 0.0 event: 0 loss: tensor(0.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 1.0 event: 10000 loss: tensor(0.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 2.0 event: 20000 loss: tensor(0.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 4.0 event: 40000 loss: tensor(0.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 5.0 event: 50000 loss: tensor(0.0821, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 6.0 event: 60000 loss: tensor(0.0736, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 2 batch 7.0 event: 70000 loss: tensor(0.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:06:49.773556
epoch: 2 mean loss: 0.07474090986646416
epoch: 3 batch 0.0 event: 0 loss: tensor(0.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 2.0 event: 20000 loss: tensor(0.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 4.0 event: 40000 loss: tensor(0.0745, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 5.0 event: 50000 loss: tensor(0.0795, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 6.0 event: 60000 loss: tensor(0.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 3 batch 7.0 event: 70000 loss: tensor(0.0680, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:09:06.312019
epoch: 3 mean loss: 0.07440444204199796
=> saveing checkpoint at epoch 3
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 4 batch 0.0 event: 0 loss: tensor(0.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 1.0 event: 10000 loss: tensor(0.0750, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 2.0 event: 20000 loss: tensor(0.0723, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 3.0 event: 30000 loss: tensor(0.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 4.0 event: 40000 loss: tensor(0.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 5.0 event: 50000 loss: tensor(0.0793, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 6.0 event: 60000 loss: tensor(0.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 4 batch 7.0 event: 70000 loss: tensor(0.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:11:22.817491
epoch: 4 mean loss: 0.07415384504785175
epoch: 5 batch 0.0 event: 0 loss: tensor(0.0799, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 1.0 event: 10000 loss: tensor(0.0761, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 2.0 event: 20000 loss: tensor(0.0698, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 3.0 event: 30000 loss: tensor(0.0770, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 4.0 event: 40000 loss: tensor(0.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 5.0 event: 50000 loss: tensor(0.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 5 batch 7.0 event: 70000 loss: tensor(0.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:13:39.316661
epoch: 5 mean loss: 0.07424311665267848
epoch: 6 batch 0.0 event: 0 loss: tensor(0.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 1.0 event: 10000 loss: tensor(0.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 2.0 event: 20000 loss: tensor(0.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 3.0 event: 30000 loss: tensor(0.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 4.0 event: 40000 loss: tensor(0.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 5.0 event: 50000 loss: tensor(0.0825, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 6.0 event: 60000 loss: tensor(0.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 6 batch 7.0 event: 70000 loss: tensor(0.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:15:55.839620
epoch: 6 mean loss: 0.07413982745458103
=> saveing checkpoint at epoch 6
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 7 batch 0.0 event: 0 loss: tensor(0.0800, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 1.0 event: 10000 loss: tensor(0.0753, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 2.0 event: 20000 loss: tensor(0.0700, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 3.0 event: 30000 loss: tensor(0.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 4.0 event: 40000 loss: tensor(0.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 5.0 event: 50000 loss: tensor(0.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 6.0 event: 60000 loss: tensor(0.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 7 batch 7.0 event: 70000 loss: tensor(0.0675, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:18:12.423011
epoch: 7 mean loss: 0.07407570320351445
epoch: 8 batch 0.0 event: 0 loss: tensor(0.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 1.0 event: 10000 loss: tensor(0.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 2.0 event: 20000 loss: tensor(0.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 3.0 event: 30000 loss: tensor(0.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 4.0 event: 40000 loss: tensor(0.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 5.0 event: 50000 loss: tensor(0.0814, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 6.0 event: 60000 loss: tensor(0.0735, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 8 batch 7.0 event: 70000 loss: tensor(0.0702, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:20:28.974372
epoch: 8 mean loss: 0.07410252058487005
epoch: 9 batch 0.0 event: 0 loss: tensor(0.0834, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 1.0 event: 10000 loss: tensor(0.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 2.0 event: 20000 loss: tensor(0.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 3.0 event: 30000 loss: tensor(0.0771, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 4.0 event: 40000 loss: tensor(0.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 5.0 event: 50000 loss: tensor(0.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 6.0 event: 60000 loss: tensor(0.0749, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 9 batch 7.0 event: 70000 loss: tensor(0.0679, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:22:45.527827
epoch: 9 mean loss: 0.07416547372533126
=> saveing checkpoint at epoch 9
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 10 batch 0.0 event: 0 loss: tensor(0.0806, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 1.0 event: 10000 loss: tensor(0.0754, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 2.0 event: 20000 loss: tensor(0.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 3.0 event: 30000 loss: tensor(0.0776, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 4.0 event: 40000 loss: tensor(0.0740, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 5.0 event: 50000 loss: tensor(0.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 6.0 event: 60000 loss: tensor(0.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 10 batch 7.0 event: 70000 loss: tensor(0.0692, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:25:02.089873
epoch: 10 mean loss: 0.07407347477603718
epoch: 11 batch 0.0 event: 0 loss: tensor(0.0829, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 1.0 event: 10000 loss: tensor(0.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 2.0 event: 20000 loss: tensor(0.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 4.0 event: 40000 loss: tensor(0.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 5.0 event: 50000 loss: tensor(0.0802, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 6.0 event: 60000 loss: tensor(0.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 11 batch 7.0 event: 70000 loss: tensor(0.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:27:18.634954
epoch: 11 mean loss: 0.074142171934918
epoch: 12 batch 0.0 event: 0 loss: tensor(0.0831, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 1.0 event: 10000 loss: tensor(0.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 2.0 event: 20000 loss: tensor(0.0691, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 4.0 event: 40000 loss: tensor(0.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 5.0 event: 50000 loss: tensor(0.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 6.0 event: 60000 loss: tensor(0.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 12 batch 7.0 event: 70000 loss: tensor(0.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:29:35.185915
epoch: 12 mean loss: 0.07415337104107785
=> saveing checkpoint at epoch 12
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 13 batch 0.0 event: 0 loss: tensor(0.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 1.0 event: 10000 loss: tensor(0.0757, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 2.0 event: 20000 loss: tensor(0.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 3.0 event: 30000 loss: tensor(0.0775, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 4.0 event: 40000 loss: tensor(0.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 5.0 event: 50000 loss: tensor(0.0809, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 6.0 event: 60000 loss: tensor(0.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 13 batch 7.0 event: 70000 loss: tensor(0.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:31:51.749455
epoch: 13 mean loss: 0.07410285465951368
epoch: 14 batch 0.0 event: 0 loss: tensor(0.0810, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 1.0 event: 10000 loss: tensor(0.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 2.0 event: 20000 loss: tensor(0.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 4.0 event: 40000 loss: tensor(0.0741, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 5.0 event: 50000 loss: tensor(0.0808, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 6.0 event: 60000 loss: tensor(0.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 14 batch 7.0 event: 70000 loss: tensor(0.0676, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:34:08.270290
epoch: 14 mean loss: 0.07407538399964861
epoch: 15 batch 0.0 event: 0 loss: tensor(0.0812, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 1.0 event: 10000 loss: tensor(0.0751, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 2.0 event: 20000 loss: tensor(0.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 4.0 event: 40000 loss: tensor(0.0744, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 5.0 event: 50000 loss: tensor(0.0813, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 6.0 event: 60000 loss: tensor(0.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 15 batch 7.0 event: 70000 loss: tensor(0.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:36:24.761533
epoch: 15 mean loss: 0.07414380381078282
=> saveing checkpoint at epoch 15
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 16 batch 0.0 event: 0 loss: tensor(0.0807, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 1.0 event: 10000 loss: tensor(0.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 2.0 event: 20000 loss: tensor(0.0693, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 4.0 event: 40000 loss: tensor(0.0746, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 5.0 event: 50000 loss: tensor(0.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 6.0 event: 60000 loss: tensor(0.0731, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 16 batch 7.0 event: 70000 loss: tensor(0.0677, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:38:41.281278
epoch: 16 mean loss: 0.07411710519034968
epoch: 17 batch 0.0 event: 0 loss: tensor(0.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 1.0 event: 10000 loss: tensor(0.0756, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 2.0 event: 20000 loss: tensor(0.0695, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 3.0 event: 30000 loss: tensor(0.0773, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 4.0 event: 40000 loss: tensor(0.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 5.0 event: 50000 loss: tensor(0.0796, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 6.0 event: 60000 loss: tensor(0.0730, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 17 batch 7.0 event: 70000 loss: tensor(0.0686, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:40:57.828635
epoch: 17 mean loss: 0.07403186240212427
epoch: 18 batch 0.0 event: 0 loss: tensor(0.0837, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 1.0 event: 10000 loss: tensor(0.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 2.0 event: 20000 loss: tensor(0.0694, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 3.0 event: 30000 loss: tensor(0.0774, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 4.0 event: 40000 loss: tensor(0.0747, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 5.0 event: 50000 loss: tensor(0.0798, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 6.0 event: 60000 loss: tensor(0.0732, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 18 batch 7.0 event: 70000 loss: tensor(0.0678, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:43:14.373416
epoch: 18 mean loss: 0.07411313671309493
=> saveing checkpoint at epoch 18
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
epoch: 19 batch 0.0 event: 0 loss: tensor(0.0816, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 1.0 event: 10000 loss: tensor(0.0752, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 2.0 event: 20000 loss: tensor(0.0697, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 3.0 event: 30000 loss: tensor(0.0772, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 4.0 event: 40000 loss: tensor(0.0743, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 5.0 event: 50000 loss: tensor(0.0803, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 6.0 event: 60000 loss: tensor(0.0733, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
epoch: 19 batch 7.0 event: 70000 loss: tensor(0.0682, device='cuda:0', dtype=torch.float64,
       grad_fn=<BinaryCrossEntropyBackward>)
time passed so far: 0:45:30.929277
epoch: 19 mean loss: 0.07417094191391449
=> saveing checkpoint at epoch 19
checkpoint is saved at: /hpcfs/bes/mlgpu/hoseinkk/MLTracking/bhabha/bhabha-files/bhabaGCN04
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19] [0.1010741  0.07661866 0.07474091 0.07440444 0.07415385 0.07424312
 0.07413983 0.0740757  0.07410252 0.07416547 0.07407347 0.07414217
 0.07415337 0.07410285 0.07407538 0.0741438  0.07411711 0.07403186
 0.07411314 0.07417094]
0:45:31.233852

real	45m44.469s
user	33m13.969s
sys	12m22.236s
